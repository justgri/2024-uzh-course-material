{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OpenAI API\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Large language models (LLMs) enable us to solve complex language problems such as ratings or classification. They provide high quality responses, but are too large for ourselves to train and run. Luckily, we can access them very easily and cheaply via API calls. Here we will do the same topic classification we did with LDA, jsut with OpenAI's GPT3.5 Turbo model.\n",
    "\n",
    "We begin by loading the package and providing the API-key that is used to bill our request to our OpenAI Account. You can create an account on https://auth.openai.com. Then create a new project and generate an API-key. Paste this API key below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "OPENAI_API_KEY =  # key"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we specify which model we want to use. In this case GPT 3.5 Turbo. We also specify parameters guiding the model how random (temperature) its answers should be and how long the response should maximally be (max_tokens)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "kwargs = {'temperature':0,\n",
    "          'max_tokens':300,\n",
    "          'model':'gpt-3.5-turbo'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we specify the query we send to the API. The content message is a general priming of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "content_message = \"You are a helpful AI assistant.\"\n",
    "openai_query_framework = \"Give me topics for all these sentences: {text}  Answer:\"\n",
    "text = \"\"\"\n",
    "    \"I love to eat pizza. Pizza is my favorite food.\",\n",
    "    \"The cat is playing with the ball.\",\n",
    "    \"I enjoy reading books on machine learning.\",\n",
    "    \"The dog is chasing the cat.\",\n",
    "    \"Pizza and pasta are popular Italian dishes.\" \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we send our query and retrieve the response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI(api_key=OPENAI_API_KEY)\n",
    "\n",
    "# ChatGPT\n",
    "kwargs['messages']=[{\"role\": \"system\", \"content\": content_message},\n",
    "                    {\"role\": \"user\", \"content\": openai_query_framework.format(text=text)},\n",
    "                ]\n",
    "response = client.chat.completions.create(**kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Pizza\n",
      "2. Cats and Play\n",
      "3. Machine Learning\n",
      "4. Dogs and Cats\n",
      "5. Italian Cuisine\n"
     ]
    }
   ],
   "source": [
    "print(response.choices[0].message.content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pp4rs",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
